{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6fa3a84",
   "metadata": {},
   "source": [
    "# Sampling Distribution\n",
    "\n",
    "********************************************************************************\n",
    "\n",
    "## Sampling distributions and Central Limit Theorem\n",
    "\n",
    "Recap of Inferential Statistics.\n",
    "\n",
    "#### Inferential Statistics\n",
    "\n",
    ">In order to assure you are comfortable with the ideas surrounding inferential statistics. The next 4 concepts are aimed at the difference between Descriptive and Inferential Statistics. Actually applying inferential statistics techniques to data will be taught in later lessons.\n",
    "\n",
    "#### Probability to Statistics\n",
    "\n",
    ">This begins a set of lessons that will be more data oriented in the way that you are applying ideas, and less probability oriented.\n",
    "\n",
    ">Often we use statistics to verify conclusions of probability through simulation. Therefore, simulation will be a large part of the way we show mathematical ideas moving forward.\n",
    "\n",
    "\n",
    "#### Comparison Descriptive and Inferential Statistics\n",
    "\n",
    ">In this section, we learned about how Inferential Statistics differs from Descriptive Statistics.\n",
    "\n",
    ">* `Descriptive statistics` is about describing our collected data using the measures discussed throughout this lesson: measures of center, measures of spread, shape of our distribution, and outliers. We can also use plots of our data to gain a better understanding.\n",
    "\n",
    "\n",
    ">* `Inferential Statistics` is about using our collected data to draw conclusions to a larger population. Performing inferential statistics well requires that we take a sample that accurately represents our population of interest.\n",
    "\n",
    ">A common way to collect data is via a survey. However, surveys may be extremely biased depending on the types of questions that are asked, and the way the questions are asked. This is a topic you should think about when tackling the first project.\n",
    "\n",
    ">We looked at specific examples that allowed us to identify the\n",
    "\n",
    ">* Population - our entire group of interest.\n",
    ">* Parameter - numeric summary about a population\n",
    ">* Sample - subset of the population\n",
    ">* Statistic numeric summary about a sample\n",
    "\n",
    "### Sampling distribution\n",
    "\n",
    ">A sampling distribution is the distribution of a statistic. Here we looked the distribution of the proportion for samples of 5 students. This is key to the ideas covered not only in this lesson, but in future lessons.\n",
    "\n",
    "### Notation\n",
    "\n",
    "![](imgs/c4_l10_01.png)\n",
    "\n",
    "<center><strong>Figure 1</strong></center>\n",
    "\n",
    "\n",
    ">We commonly use Greek symbols as parameters and lowercase letters as the corresponding statistics. Sometimes in the literature, you might also see the same Greek symbols with a \"hat\" to represent that this is an estimate of the corresponding parameter.\n",
    "\n",
    "### Other Sampling Distribution\n",
    "\n",
    "It is possible to use other statistics.\n",
    "\n",
    "* Standard Deviation\n",
    "* Variance\n",
    "* Difference in Means\n",
    "\n",
    "The difference between parameters and statistics is the last one is varies and the first is fixed.\n",
    "\n",
    "### Law of Large Number\n",
    "\n",
    "This theorem preconizes the greater the number of the samples/trials the average of this sample will be close to the population mean. This is the reason we have simulated samples sizes of 10,000.\n",
    "\n",
    "* Increasing the size of the sample the mean of this sample will be closer to the population mean.\n",
    "\n",
    "[Read more in Wikipedia][wiki_lln] and [Investopedia][investopedia_lln]\n",
    "\n",
    "[wiki_lln]: https://en.wikipedia.org/wiki/Law_of_large_numbers\n",
    "[investopedia_lln]: https://www.investopedia.com/terms/l/lawoflargenumbers.asp\n",
    "\n",
    "### Central Limit Theorem\n",
    "\n",
    "Quite similar with the LLN theorem, but this is related to the shape of sample. It is necessary to plot a histogram to see the miracle.\n",
    "\n",
    "* Increasing the size of the sample the shape of the sample will be closer to a normal distribution.\n",
    "\n",
    "![](imgs/c4_l10_02.png)\n",
    "\n",
    "<center><strong>Figure 2</strong></center>\n",
    "\n",
    ">The Central Limit Theorem states that with a large enough sample size the sampling distribution of the mean will be normally distributed.\n",
    "\n",
    ">The Central Limit Theorem actually applies for these well known statistics:\n",
    "\n",
    ">1. Sample means ($\\bar x$)\n",
    ">2. Sample proportions ($p$)\n",
    ">3. Difference in sample means ($\\bar x_1 - \\bar x_2$)\n",
    ">4. Difference in sample proportions ($p_1 - p_2$)\n",
    "\n",
    "But is not applied to:\n",
    "\n",
    "1. Variance or Standard Deviation\n",
    "2. Correlation coefficient\n",
    "3. Maximum value\n",
    "\n",
    ">And it applies for additional statistics, **but it doesn't apply for all statistics!**. You will see more on this towards the end of this lesson.\n",
    "\n",
    "Examples CLT in Figures 3 and 4.\n",
    "\n",
    "![](imgs/c4_l10_03.png)\n",
    "\n",
    "<center><strong>Figure 3</strong></center>\n",
    "\n",
    "![](imgs/c4_l10_04.png)\n",
    "\n",
    "<center><strong>Figure 4</strong></center>\n",
    "\n",
    "Varying the value of the sample from 3 to 100, the bell shape could be identified.\n",
    "\n",
    "### Bootstrapping\n",
    "\n",
    ">Bootstrapping is a technique where we sample from a group with replacement.\n",
    "\n",
    ">We can use bootstrapping to simulate the creation of sampling distribution, which you did many times in this lesson.\n",
    "\n",
    ">By bootstrapping and then calculating repeated values of our statistics, we can gain an understanding of the sampling distribution of our statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d451c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
